{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Quick attempt to train a model"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import fastai\nfrom fastai import *\nfrom fastai.vision import *\nfrom sklearn.model_selection import train_test_split\nimport time\n\nverbose = False  # should print out extra details?\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2f62a308d5fd9f41969fba88781578a320ccb4e"},"cell_type":"code","source":"bs = 64\nnum_workers = 0  # Anything greater than zero will get error: DataLoader worker (pid 57) is killed by signal: Bus error\nimage_size = 224","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b442e91f2ddebcf56fff7ec499751068531d41c5"},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fc2900060731e93fedf453b0de487a5886d16cc"},"cell_type":"code","source":"data_fp = Path('../input')\ndata_train = data_fp/'train'\ndata_test = data_fp/'test'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea2442b96428d55f9c701fbea5c0b993d361f36b"},"cell_type":"markdown","source":"## Looking at the data"},{"metadata":{"trusted":true,"_uuid":"0cf7f910b8e68ae90d377c81df17d9a9e3c6815a"},"cell_type":"code","source":"labels = pd.read_csv(data_fp/'train.csv')\nprint(labels.shape)\nprint(f'Number of classes: {len(labels.Id.unique()):,}')\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b12c3ece12d2b89ba88904d9bb2311643e58d318"},"cell_type":"markdown","source":"## Split Data into training and validation set"},{"metadata":{"trusted":true,"_uuid":"5fbfe2925d919c3cd447ea5be5ca15f78c238b22"},"cell_type":"code","source":"class_counts = labels.Id.value_counts(sort=True, ascending=True)\nprint(f'The number of images: {class_counts.sum():,}')\nprint('{}'.format('='*20))\nprint(f'Number of classes with only one image: {sum(class_counts == 1):,}')\nprint(f'Percentage of classes with one image: {sum(class_counts == 1)/len(labels.Id.unique()):.0%}')\nprint('{}'.format('='*20))\nprint(f'Number of new_whate image: {class_counts[\"new_whale\"].sum():,}')\nprint(f'Percentage of images are new_whale: {class_counts[\"new_whale\"]/class_counts.sum()*100:0.0f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"577aa1b24078460004dacf5c6d9d15228d935e48"},"cell_type":"code","source":"class_counts[::-1][:5]  # top five most common class","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59a6fb12365d70d808e92e91d642ed94c108dc5c"},"cell_type":"markdown","source":"## Stratified Split"},{"metadata":{"trusted":true,"_uuid":"f5e6dd414dd4daa7bf1bde08ce57d2e3f5a9eecd"},"cell_type":"code","source":"start_time = time.time()\n## stratify sampling that can handle \ntrain_idx, val_idx = pd.Series(), pd.Series()\nfor name, group in labels.reset_index()[['index', 'Id']].groupby(['Id']):\n    ## if a class only have 1 sample, just return that one\n    if group.shape[0] == 1:\n        train, val = group['index'], []\n    ## split each group randomly and obtain their index\n    else:\n        train, val = train_test_split(group['index'], test_size=0.2, random_state=None)\n    train_idx = train_idx.append(train)\n    val_idx = val_idx.append(val)\n    \nprint(f'It took {int(time.time() - start_time)} seconds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913de72bffa3d29675a0499f823ebc5000431dd5"},"cell_type":"code","source":"train_idx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec50362db3536ff851610cb5de99c95b9538336b"},"cell_type":"code","source":"## assess that the number of class are all accounted for in the training indexing\nassert len(labels.loc[train_idx, 'Id'].unique()) == len(labels.Id.unique())\nprint('Number of class {}: {}'.format(len(labels.loc[train_idx, 'Id'].unique()), len(labels['Id'].unique())))\nprint('Percent of training split: {:.0%}'.format(len(train_idx)/labels.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9713210885fabd5cb185a1930677156e4a244418"},"cell_type":"markdown","source":"## Create ImageDataBunch"},{"metadata":{"trusted":true,"_uuid":"ec7d6e12f2efe51b02b24fbbf8af9cbcca1b1138"},"cell_type":"code","source":"tfms = get_transforms(flip_vert=False, max_zoom=1)  ## remove vertical and zooming\nif verbose: tfms  ## list of transformations done to the images. tfms[0] is for training and tfms[1] is for validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"678110c86156f60e6d16be39cae293dd365de50c"},"cell_type":"code","source":"src = (ImageItemList.from_df(path=data_fp, df=labels, cols='Image', folder='train')\n                     # images' filepath are in a dataframe with column name 'Image'\n                    .split_by_idx(val_idx)\n                    # validations are not random and determined by the row indices\n                    .label_from_df(cols='Id')\n                    # classes for the images are in a dataframe with column name 'Id'\n                    .add_test_folder())\n                    # images to be use for inferences to the kaggle competition\nif verbose: print(f'Type({type(src)})')\nif verbose : print(src)  # show a summary of the datasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33369a94c55028baa3a4482b616cc7be56967965"},"cell_type":"code","source":"def get_data(size, bs, padding_mode='reflection'):\n    return (src.transform(tfms, \n                          size=size,\n                          resize_method=ResizeMethod.PAD,\n                          padding_mode=padding_mode)\n                .databunch(bs=bs, num_workers=num_workers)\n                # creates a dataloader\n                .normalize(imagenet_stats))\n                # normalize the whale images with imagenet's mean and std because we are using a pretrained model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"727d2d879614892d83ff9b51b26cb006dd4c65a0"},"cell_type":"code","source":"data = get_data(image_size, bs, 'border')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9bcab0235c78aa51cdad3e97dd514faa2659ede"},"cell_type":"code","source":"# Display examples of the transformation on a single image\ndef _plot(i,j,ax):\n    x,y = data.train_ds[idx]\n    x.show(ax,y=y)\n\nidx = np.random.randint(len(data.train_ds))\nplot_multi(_plot, 3, 3, figsize=(8,8))  ## show how the image is being transformed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17b477a5efd0000338f86bf4df7bd24afa74e055"},"cell_type":"code","source":"open_image(data.train_ds.items[idx])  ## orginal image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"632ff562fe1547f84deef0ac5f258632dfb32cdf"},"cell_type":"code","source":"#data.show_batch(rows=2, figsize=(8,8))  # this crashes the kernel","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31a27195f3e6beb49ac99d252aa2f4e5b7243118"},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true,"_uuid":"3b879a988a8175ba5142c8f38006d430c2d1304d"},"cell_type":"code","source":"def mapr(input: torch.Tensor, targs: torch.LongTensor, mapn: int):\n    \"Compute the mean average precision\"\n    n = targs.shape[0]  # number for samples\n    input = input.argsort(dim=-1, descending=True)[:,:mapn]\n    targs = targs.view(n, -1)\n    return ((input == targs).float()/torch.arange(1,mapn+1, device=input.device).float()).sum(dim=-1).mean()\n\nmap5 = partial(mapr, mapn=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59f8868085fa5a93c4784394fe2b87da5b90daff"},"cell_type":"code","source":"learn = create_cnn(data=data, arch=models.resnet50, metrics=[accuracy, map5], model_dir = '/tmp/models')\n# make sure your kernel has internet access\n# model_dir is needed because it will try to make a models in the input folder which is Read-Only","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f9e1a70d3b3ba325f26ed50f61bf3ff63991738"},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"587a7051109e331580c43420d661a49b75c757a3"},"cell_type":"code","source":"learn.fit(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cac9e6e39ea6d3102dd1d86ff422e03f8f8c6984"},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa063fdcce20b82ea0b22df4c9a4a0d158daf91c"},"cell_type":"code","source":"learn.recorder.plot_lr(show_moms=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5436358057434e6ffbac704549943e9944488cde"},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7215f498f6194cd987a5cc85467570aa8d8b535c"},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9a58043bf813245e3eee1af411dea7cf32f5942"},"cell_type":"code","source":"pred, _ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78a890bae439424ab1410fd26102c96f95178335"},"cell_type":"code","source":"def create_submission(preds, data, path, name, mapn=5):\n    preds_sort = preds.argsort(dim=-1, descending=True)[:,:mapn]\n    cls_np = np.asarray(data.classes)\n    (pd.DataFrame({\"Image\": [fn.name for fn in data.test_ds.items],\n                  \"Id\": [\" \".join(cls_np[idx]) for idx in preds_sort.numpy()]})\n        .to_csv(path/name, index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ab706bc9785292ffbe21949da8a11de3577a3ed"},"cell_type":"code","source":"sub_fp = Path(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a10d0f53d0c74a447f9358cc50e27109bd13e4dc"},"cell_type":"code","source":"create_submission(pred, learn.data, sub_fp,'testing2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc86cba701e9f754cdb43d934031825aedf2299f"},"cell_type":"code","source":"pd.read_csv(sub_fp/'testing2.csv').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e31d61fda80103a65a50f36cd4a0834bab5814af"},"cell_type":"code","source":"# !df -h  # display compute specs","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}